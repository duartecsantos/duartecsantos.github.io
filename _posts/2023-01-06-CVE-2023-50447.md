---
layout: post
title: Arbitrary Code Execution in Pillow
subtitle: CVE-2023-50447
tags: [CVE]
---

During Checkmarxâ€™s Research Group routine activities, we often conduct security assessments on open-source technologies to refine both our tools and our skillset. During one of these activities, I identified a Critical vulnerability in [Pillow](https://github.com/python-pillow/Pillow). This vulnerability was later assigned [CVE-2023-50447](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-50447).

{: .box-error}
**CVSS v3:** 9.0 - [AV:N/AC:H/PR:N/UI:N/S:C/C:H/I:H/A:H](https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:H/PR:N/UI:N/S:C/C:H/I:H/A:H&version=3.1)

Serving as a successor to the Python Imaging Library (PIL), Pillow is a Python imaging library that provides a comprehensive set of tools for opening, manipulating, and saving various image file formats. It is widely used in web development, data analysis, computer vision, and other domains, providing a user-friendly interface. With support for numerous image formats and a rich set of features, Pillow is a go-to solution for developers and designers working with images in Python applications.

This vulnerability is present in the `PIL.ImageMath.eval` function in versions up to and including 10.1.0. The `ImageMath` module can be used to evaluate image expressions and it provides a single `eval` function, which takes an expression string and one or more images. You can read more about this function and how it works in the Pillow [documentation](https://pillow.readthedocs.io/en/stable/reference/ImageMath.html#PIL.ImageMath.eval). Here is the usage example given in the documentation, which includes two of the built-in functions â€” `convert` and `min`:

```python
from PIL import Image, ImageMath

with Image.open('image1.jpg') as im1:
    with Image.open('image2.jpg') as im2:
        out = ImageMath.eval("convert(min(a, b), 'L')", a=im1, b=im2)
        out.save('result.png')
```

It's not the first time that a vulnerability has been discovered that leads to arbitrary code execution in this function. Versions prior to 9.0.1 were vulnerable to [CVE-2022-22817](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-22817). In those versions, `PIL.ImageMath.eval` allowed the evaluation of arbitrary expressions, and so it was trivial to get arbitrary code execution simply by controlling the expression passed to the function â€” e.g. `ImageMath.eval('exec(...)')`. 

To prevent this vulnerability, a [commit](https://github.com/python-pillow/Pillow/commit/8531b01d6cdf0b70f256f93092caa2a5d91afc11) was made with the aim of restricting the builtins available to `PIL.ImageMath.eval()`. Let's review this snippet of Pillow's code with the filter responsible for ensuring that we're not evaluating arbitrary objects:

```python
code = compile(expression, "<string>", "eval")
...
for name in code.co_names:
    if name not in args and name != "abs":
        msg = f"'{name}' not allowed"
        raise ValueError(msg)
```

Here, `expression` refers to the first parameter of `PIL.ImageMath.eval`, i.e. the string containing a Python-style expression, and `args` contains values to add to the evaluation context, which includes some built-in functions as well as the arguments passed to the second parameter of `PIL.ImageMath.eval` so that they can be referenced inside.
`compile` is a Python built-in function ([docs](https://docs.python.org/3/library/functions.html#compile)) that compiles an expression into a code or AST object, so that it can later be executed by `exec` or `eval`. `co_names` is an attribute of a code object that returns a tuple containing the names in the expression â€” actually, to be more precise, it's in the bytecode object, but saying it's in the expression is a simpler way of explaining what it does.

Now, what is this implementation doing? It's checking the names in the expression against an allowlist (i.e. `args`). On the surface, it seems like a good solution, but like everything in application security, the devil is in the details... 

What would happen if we could control this allowlist? We'd be able to use whatever names we wanted and thus achieve arbitrary code execution! Unfortunately, it's not that simple... We can't just add an `exec` to the `PIL.ImageMath.eval` context and use the payload we saw earlier in CVE-2022-22817, because that `exec` won't be the Python function, but an `Image` passed in as an argument. 

```python
ImageMath.eval("exec(...)", exec=Image.open(...))
```

Hmm... Now what? We need to get permission to use the names we want and at the same time we need those names to be the functions we actually want to call, not just the object passed as an argument. It was at this point that I remembered the challenges of some CTFs I played in the past related to Python jail/sandbox escapes. To bypass this we can use Python's *dunder* or magic methods! Allow me to explain... Although we can't call arbitrary functions in the context of `eval`, by controlling this allowlist, we can call arbitrary methods inside any present object. This is because the name of a method has a different context from the name of a variable, for example, if we take the code above it's easy to see that the `exec` in `exec('whoami')` is different from `Palpatine.exec('Order 66')`. Our `exec` in the latter case won't be "replaced" by the object passed to the `PIL.ImageMath.eval` context since it is the `exec` attribute corresponding to the `Palpatine` object and not a standalone object. 

In short, we have the ability to call arbitrary attributes. This, along with the existence of *dunder* methods, can be used to achieve arbitrary code execution! [HackTricks](https://book.hacktricks.xyz/generic-methodologies-and-resources/python/bypass-python-sandboxes#discover-arbitrary-execution) has some payloads that we can use for this.

That said, exploiting this vulnerability has some obstacles in real scenarios which result in high attack complexity and reduced overall risk: it is necessary for the images passed to the environment to be able to have names like "\_\_class\_\_". Although this is a valid file name, applications need to be able to save images without changing this name. For instance, things like adding the file extension (e.g. jpg) to the filename would already prevent this vulnerability from being exploited.

It's finally time to write a Proof Of Concept (POC). For this POC we need 5 images with the names: "\_\_class\_\_", "\_\_bases\_\_", "\_\_subclasses\_\_", "load_module", and "system". Note that these are valid file names on any OS.

```python
from PIL import Image, ImageMath

image1 = Image.open('__class__')
image2 = Image.open('__bases__')
image3 = Image.open('__subclasses__')
image4 = Image.open('load_module')
image5 = Image.open('system')

expression = "().__class__.__bases__[0].__subclasses__()[104].load_module('os').system('whoami')"

environment = {
    image1.filename: image1,
    image2.filename: image2,
    image3.filename: image3,
    image4.filename: image4,
    image5.filename: image5
}

ImageMath.eval(expression, **environment)
```

I reported this vulnerability to the Pillow maintainers and it was fixed in version 10.2.0, as described in the [Release Notes](https://pillow.readthedocs.io/en/stable/releasenotes/10.2.0.html#imagemath-eval-restricted-environment-keys). I want to take this opportunity to thank them for their efficient communication!

And with that, we come to the end of this blogpost. Thanks for reading, I hope it was interesting ðŸ™‚

